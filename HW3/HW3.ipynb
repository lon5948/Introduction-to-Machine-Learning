{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3: Decision Tree, AdaBoost and Random Forest\n",
    "In hw3, you need to implement decision tree, adaboost and random forest by using only numpy, then train your implemented model by the provided dataset. TA will use the on-hold test label to evaluate your model performance.\n",
    "\n",
    "Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling `sklearn.tree.DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Gini Index or Entropy is often used for measuring the “best” splitting of the data. Please compute the Entropy and Gini Index of provided data. Please use the formula from [page 5 of hw3 slides](https://docs.google.com/presentation/d/1kIe_-YZdemRMmr_3xDy-l0OS2EcLgDH7Uan14tlU5KE/edit#slide=id.gd542a5ff75_0_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(sequence, weight=None):\n",
    "    if weight is None: # for general decison tree\n",
    "        types, counts = np.unique(sequence, return_counts=True)\n",
    "        square = [np.square(c/len(sequence)) for c in counts]\n",
    "    else: # for sequence with weight\n",
    "        weight_sum = np.sum(weight)\n",
    "        types = np.unique(sequence)\n",
    "        weights = []\n",
    "        # compute sum of weight in each types\n",
    "        for t in types:\n",
    "            weights.append(np.sum(weight[np.where(sequence==t)]))\n",
    "        square = [np.square(w/weight_sum) for w in weights]\n",
    "    return 1 - np.sum(square)\n",
    "\n",
    "def entropy(sequence, weight=None):\n",
    "    if weight is None: # for general decison tree\n",
    "        types, counts = np.unique(sequence, return_counts=True)\n",
    "        entro = [(c/len(sequence)) * np.log2(c/len(sequence)) for c in counts]\n",
    "    else: # for sequence with weight\n",
    "        weight_sum = np.sum(weight)\n",
    "        types = np.unique(sequence)\n",
    "        weights = []\n",
    "        # compute sum of weights in each types\n",
    "        for t in types:\n",
    "            weights.append(np.sum(weight[np.where(sequence==t)]))\n",
    "        entro = [(w/weight_sum) * np.log2(w/weight_sum) for w in weights]\n",
    "    return -np.sum(entro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = class 1,\n",
    "# 2 = class 2\n",
    "data = np.array([1,2,1,1,1,1,2,2,1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini of data is  0.4628099173553719\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini of data is \", gini(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of data is  0.9456603046006401\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy of data is \", entropy(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "It is a binary classifiation dataset that classify if price is high or not for a cell phone, the label is stored in `price_range` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 21)\n",
      "(300, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1583</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>942</td>\n",
       "      <td>1651</td>\n",
       "      <td>1704</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>745</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.8</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>1538</td>\n",
       "      <td>2459</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.7</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>1504</td>\n",
       "      <td>1799</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3</td>\n",
       "      <td>164</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>873</td>\n",
       "      <td>1394</td>\n",
       "      <td>1944</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1649</td>\n",
       "      <td>1829</td>\n",
       "      <td>2855</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0           1583     1          2.1         1  11       0          14    0.7   \n",
       "1            745     1          0.6         1   5       0          35    0.8   \n",
       "2            832     0          0.7         1   2       1          39    0.7   \n",
       "3           1175     1          1.3         0   2       0          19    0.3   \n",
       "4            695     0          0.5         0  18       1          12    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        148        7  ...        942      1651  1704    17    13          2   \n",
       "1        102        8  ...         89      1538  2459    14     1         16   \n",
       "2        103        4  ...        125      1504  1799     5     2         11   \n",
       "3        164        7  ...        873      1394  1944     9     4          9   \n",
       "4        196        2  ...       1649      1829  2855    16    13          7   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        1             0     1            1  \n",
       "1        1             1     0            0  \n",
       "2        1             0     1            0  \n",
       "3        1             1     0            0  \n",
       "4        1             1     1            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "val_df = pd.read_csv('val.csv')\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train_df.iloc[:, 0:20].values\n",
    "ytrain = train_df['price_range'].values\n",
    "\n",
    "xtest = val_df.iloc[:, 0:20].values\n",
    "ytest = val_df['price_range'].values\n",
    "\n",
    "columns = train_df.iloc[:, 0:20].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Implement the Decision Tree algorithm (CART, Classification and Regression Trees) and trained the model by the given arguments, and print the accuracy score on the validation data. You should implement two arguments for the Decision Tree algorithm\n",
    "1. **criterion**: The function to measure the quality of a split. Your model should support `gini` for the Gini impurity and `entropy` for the information gain. \n",
    "2. **max_depth**: The maximum depth of the tree. If `max_depth=None`, then nodes are expanded until all leaves are pure. `max_depth=1` equals to split data once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, ans=None, depth=None):\n",
    "        self.depth = depth # record depth of node, it must < max_depth\n",
    "        self.attribute = 0 # record attribute index of node\n",
    "        self.threshold = 0 # record threshold of node, and decide left or right node to be the next node\n",
    "        self.left_node = None # record left node of node\n",
    "        self.right_node = None # record right node of node\n",
    "        self.ans = ans # record label of node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, criterion='gini', max_depth=None, max_features=None):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features # for random forest\n",
    "\n",
    "    def fit(self, x_data, y_data, weight=None):\n",
    "        self.attributes = list(range(0,x_data.shape[1])) # all the index of attributes(0 ~ 19)\n",
    "        self.feature_importance = np.zeros(x_data.shape[1]) # compute feature importance \n",
    "        self.root = self.generate_tree(x_data, y_data, weight) # record the root of the tree\n",
    "\n",
    "    def generate_tree(self, x_data, y_data, weight, depth=0):\n",
    "        # which class is most of the data in \n",
    "        answers, counts = np.unique(y_data, return_counts=True)\n",
    "        ans = answers[np.argmax(counts)]\n",
    "        node = Node(ans, depth)\n",
    "        # stop criteria:\n",
    "        # 1. The data in each leaf-node belongs to the same class\n",
    "        # 2. Depth of the tree is equal to max_depth\n",
    "        if len(answers) > 1 and (self.max_depth is None or node.depth < self.max_depth):\n",
    "            # find best attribute and best threshold\n",
    "            threshold, attribute = self.split_attribute(x_data, y_data, weight)\n",
    "            if attribute is not None and threshold is not None:\n",
    "                attrdata = x_data[:,attribute] # all data in best attribute\n",
    "                node.attribute = attribute\n",
    "                node.threshold = threshold\n",
    "                self.feature_importance[attribute] += 1 # raise the importance of best attribute\n",
    "                # all data seperate to left data and right data \n",
    "                left_xdata = x_data[np.where(attrdata < threshold)]\n",
    "                left_ydata = y_data[np.where(attrdata < threshold)]\n",
    "                right_xdata = x_data[np.where(attrdata >= threshold)]\n",
    "                right_ydata = y_data[np.where(attrdata >= threshold)]\n",
    "                if weight is not None:\n",
    "                    # in Adaboost, all weight seperate to left weight and right weight \n",
    "                    left_weight = weight[np.where(attrdata < threshold)]\n",
    "                    right_weight = weight[np.where(attrdata >= threshold)]\n",
    "                else:\n",
    "                    left_weight = None\n",
    "                    right_weight = None\n",
    "                # generate left tree and right tree\n",
    "                node.left_node = self.generate_tree(left_xdata, left_ydata, left_weight, depth+1)\n",
    "                node.right_node = self.generate_tree(right_xdata, right_ydata, right_weight, depth+1)\n",
    "        return node\n",
    "\n",
    "    def split_attribute(self, x_data, y_data, weight):\n",
    "        best_attribute = None\n",
    "        best_threshold = None\n",
    "        if self.criterion == 'gini':\n",
    "            min_criterion = gini(y_data, weight)\n",
    "        elif self.criterion == 'entropy':\n",
    "            min_criterion = entropy(y_data, weight)\n",
    "        # in random forest, num of attributes can be selected\n",
    "        if self.max_features is not None:\n",
    "            chosen_attrs = np.random.choice(self.attributes, size=self.max_features, replace=False)\n",
    "        else:\n",
    "            chosen_attrs = self.attributes\n",
    "        # find best attribute\n",
    "        for attr in chosen_attrs:\n",
    "            attrdata = x_data[:,attr] # all data in this attribute\n",
    "            thresholds = np.unique(attrdata) # all possible threshold in this attribute\n",
    "            # find best threshold in this attribute\n",
    "            for threshold in thresholds:\n",
    "                # all data seperate to left data and right data\n",
    "                left_ydata = y_data[np.where(attrdata < threshold)]\n",
    "                right_ydata = y_data[np.where(attrdata >= threshold)]\n",
    "                if weight is not None:\n",
    "                    # all weight seperate to weight data and weight data\n",
    "                    left_weight = weight[np.where(attrdata < threshold)]\n",
    "                    right_weight = weight[np.where(attrdata >= threshold)]\n",
    "                    # compute weight ratio of left node and right node\n",
    "                    left_ratio = np.sum(left_weight)/np.sum(weight)\n",
    "                    right_ratio = np.sum(right_weight)/np.sum(weight)\n",
    "                else:\n",
    "                    # without weight\n",
    "                    left_weight = None\n",
    "                    right_weight = None\n",
    "                    # compute the proportion of the number of left node and right node\n",
    "                    left_ratio = len(left_ydata)/len(attrdata)\n",
    "                    right_ratio = len(right_ydata)/len(attrdata)\n",
    "\n",
    "                if self.criterion == 'gini':\n",
    "                    left_criterion = gini(left_ydata, left_weight)\n",
    "                    right_criterion = gini(right_ydata, right_weight)\n",
    "                elif self.criterion == 'entropy':\n",
    "                    left_criterion = entropy(left_ydata, left_weight)\n",
    "                    right_criterion = entropy(right_ydata, right_weight)\n",
    "                # compute lm' \n",
    "                crite = left_criterion * left_ratio + right_criterion * right_ratio\n",
    "                if crite < min_criterion:\n",
    "                    min_criterion = crite\n",
    "                    best_threshold = threshold\n",
    "                    best_attribute = attr\n",
    "        return best_threshold, best_attribute\n",
    "        \n",
    "\n",
    "    def predict(self, x_data):\n",
    "        y_pred = []\n",
    "        for i in range(len(x_data)):\n",
    "            node = self.root\n",
    "            # if node.left_node is None means leaf node, return the label directly \n",
    "            while node.left_node is not None: \n",
    "                if x_data[i][node.attribute] < node.threshold:\n",
    "                    node = node.left_node\n",
    "                else:\n",
    "                    node = node.right_node\n",
    "            y_pred.append(node.ans)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Using `criterion=gini`, showing the accuracy score of validation data by `max_depth=3` and `max_depth=10`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_depth3 = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_depth10 = DecisionTree(criterion='gini', max_depth=10) # highest acc: max_depth=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.92\n",
      "accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "clf_depth3.fit(xtrain, ytrain)\n",
    "ypred = clf_depth3.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))\n",
    "\n",
    "clf_depth10.fit(xtrain, ytrain)\n",
    "ypred = clf_depth10.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Using `max_depth=3`, showing the accuracy score of validation data by `criterion=gini` and `criterion=entropy`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gini = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_entropy = DecisionTree(criterion='entropy', max_depth=3) #highest acc: max_depth=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.92\n",
      "accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "clf_gini.fit(xtrain, ytrain)\n",
    "ypred = clf_gini.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))\n",
    "\n",
    "clf_entropy.fit(xtrain, ytrain)\n",
    "ypred = clf_entropy.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Your decisition tree scores should over **0.9**. It may suffer from overfitting, if so, you can tune the hyperparameter such as `max_depth`\n",
    "- Note: You should get the same results when re-building the model with the same arguments,  no need to prune the trees\n",
    "- Hint: You can use the recursive method to build the nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Plot the [feature importance](https://sefiks.com/2020/04/06/feature-importance-in-decision-trees/) of your Decision Tree model. You can get the feature importance by counting the feature used for splitting data.\n",
    "\n",
    "- You can simply plot the **counts of feature used** for building tree without normalize the importance. Take the figure below as example, outlook feature has been used for splitting for almost 50 times. Therefore, it has the largest importance\n",
    "\n",
    "![image](https://i2.wp.com/sefiks.com/wp-content/uploads/2020/04/c45-fi-results.jpg?w=481&ssl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Feature importance\")\n",
    "plt.ylabel('attribute')\n",
    "plt.xlabel('counts')\n",
    "plt.barh(columns, clf_depth10.feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "implement the AdaBooest algorithm by using the CART you just implemented from question 2 as base learner. You should implement one arguments for the AdaBooest.\n",
    "1. **n_estimators**: The maximum number of estimators at which boosting is terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, n_estimators):\n",
    "        self.n_estimators = n_estimators # num of weak classifier\n",
    "        self.weak_clfs = [] # record weak classifier\n",
    "        self.alphas = [] # record alpha\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        # initial weight\n",
    "        w = np.ones(len(x_data))/len(x_data)\n",
    "        # iterate each weak classifier\n",
    "        for ind in range(self.n_estimators):\n",
    "            # weak classifier is a decision tree with max_depth=1\n",
    "            clf = DecisionTree(criterion=\"gini\", max_depth=1) \n",
    "            clf.fit(x_data, y_data, weight=w) # training\n",
    "            pred = clf.predict(x_data) # testing\n",
    "            self.weak_clfs.append(clf)\n",
    "            # if misclassified, errorList will append 1, otherwise, 0 will be added\n",
    "            errorList = [int(value) for value in (pred!=y_data)]\n",
    "            # sum up the weight which is misclassified \n",
    "            error = np.dot(w, errorList)\n",
    "            # compute alpha\n",
    "            alpha = (1/2) * np.log((1 - error)/error)\n",
    "            self.alphas.append(alpha)\n",
    "            # update weight\n",
    "            w = np.multiply(w, np.exp([-alpha if e==0 else alpha for e in errorList]))\n",
    "            w = w / np.sum(w)\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        # prediction from each weak classifier\n",
    "        weak_pred = np.array([clf.predict(x_data) for clf in self.weak_clfs])\n",
    "        ans = np.zeros(weak_pred.shape)\n",
    "        # iterate prediction from each weak classifier\n",
    "        for ind in range(len(weak_pred)):\n",
    "            p = np.array([wp if wp == 1 else -1 for wp in weak_pred[ind]])\n",
    "            ans[ind] = self.alphas[ind] * p\n",
    "        # sum up prediction in each weak classifier -> strong classifier\n",
    "        sign_ans = np.sign(np.sum(ans, axis=0))\n",
    "        # final prediction\n",
    "        ret = np.array([1 if sa == 1 else 0 for sa in sign_ans])\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1\n",
    "Show the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_n10 = AdaBoost(n_estimators=10)\n",
    "ada_n100 = AdaBoost(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.95\n",
      "accuracy: 0.9766666666666667\n"
     ]
    }
   ],
   "source": [
    "ada_n10.fit(xtrain, ytrain)\n",
    "ypred = ada_n10.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))\n",
    "\n",
    "ada_n100.fit(xtrain, ytrain)\n",
    "ypred = ada_n100.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "implement the Random Forest algorithm by using the CART you just implemented from question 2. You should implement three arguments for the Random Forest.\n",
    "\n",
    "1. **n_estimators**: The number of trees in the forest. \n",
    "2. **max_features**: The number of random select features to consider when looking for the best split\n",
    "3. **bootstrap**: Whether bootstrap samples are used when building tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    def __init__(self, n_estimators, max_features, bootstrap=True, criterion='gini', max_depth=None):\n",
    "        self.n_estimators = n_estimators # num of tree\n",
    "        self.max_features = int(max_features) # num of attributes can be decided\n",
    "        self.bootstrap = bootstrap # boostrap samples be used or not\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.forest = [] # record each tree\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        for ind in range(self.n_estimators):\n",
    "            x_inp = x_data\n",
    "            y_inp = y_data\n",
    "            # if bootstrap is True, random choose data to be the new training data\n",
    "            if self.bootstrap is True:\n",
    "                ind = np.random.choice(list(range(0,x_data.shape[0])), size=x_data.shape[0], replace=True)\n",
    "                x_inp = x_data[ind]\n",
    "                y_inp = y_data[ind]\n",
    "            # create decision tree\n",
    "            tree = DecisionTree(criterion=self.criterion, max_depth=self.max_depth, max_features=self.max_features)\n",
    "            tree.fit(x_inp, y_inp)\n",
    "            self.forest.append(tree)\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        # prediction from each tree\n",
    "        pred = np.array([tree.predict(x_data) for tree in self.forest])\n",
    "        ypred = []\n",
    "        # use majority votes to get the final prediction\n",
    "        for ind in range(len(x_data)):\n",
    "            types, counts = np.unique(pred[:, ind], return_counts=True)\n",
    "            ypred.append(types[np.argmax(counts)])\n",
    "        return np.array(ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1\n",
    "Using `criterion=gini`, `max_depth=None`, `max_features=sqrt(n_features)`, showing the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_10tree = RandomForest(n_estimators=10, max_features=np.sqrt(xtrain.shape[1]))\n",
    "clf_100tree = RandomForest(n_estimators=100, max_features=np.sqrt(xtrain.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.91\n",
      "accuracy: 0.9433333333333334\n"
     ]
    }
   ],
   "source": [
    "clf_10tree.fit(xtrain, ytrain)\n",
    "ypred = clf_10tree.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))\n",
    "\n",
    "clf_100tree.fit(xtrain, ytrain)\n",
    "ypred = clf_100tree.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2\n",
    "Using `criterion=gini`, `max_depth=None`, `n_estimators=10`, showing the accuracy score of validation data by `max_features=sqrt(n_features)` and `max_features=n_features`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_random_features = RandomForest(n_estimators=10, max_features=np.sqrt(xtrain.shape[1]))\n",
    "clf_all_features = RandomForest(n_estimators=10, max_features=xtrain.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9266666666666666\n",
      "accuracy: 0.9633333333333334\n"
     ]
    }
   ],
   "source": [
    "clf_random_features.fit(xtrain, ytrain)\n",
    "ypred = clf_random_features.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))\n",
    "\n",
    "clf_all_features.fit(xtrain, ytrain)\n",
    "ypred = clf_all_features.predict(xtest)\n",
    "print(\"accuracy:\",accuracy_score(ypred, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Use majority votes to get the final prediction, you may get slightly different results when re-building the random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Train and tune your model on a real-world dataset\n",
    "Try you best to get higher accuracy score of your model. After parameter tuning, you can train your model on the full dataset (train + val).\n",
    "- Feature engineering\n",
    "- Hyperparameter tuning\n",
    "- Implement any other ensemble methods, such as gradient boosting. Please note that you **can not** call any package. Also, only ensemble method can be used. Neural network method is not allowed to used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_your_model(data):\n",
    "    x_data = data.iloc[:, 0:20].values\n",
    "    y_data = data['price_range'].values\n",
    "    model = RandomForest(n_estimators=200, max_features=x_data.shape[1], max_depth=9, criterion='entropy')  \n",
    "    model.fit(x_data, y_data)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('train.csv')\n",
    "df2 = pd.read_csv('val.csv')\n",
    "train_df = pd.concat([df1, df2], ignore_index=True, sort=False)\n",
    "\n",
    "my_model = train_your_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('x_test.csv').values\n",
    "y_pred = my_model.predict(x_test)\n",
    "np.save('y_pred.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (500, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary\n",
    "If you have trouble to implement this homework, TA strongly recommend watching [this video](https://www.youtube.com/watch?v=LDRbO9a6XPU), which explains Decision Tree model clearly. But don't copy code from any resources, try to finish this homework by yourself! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT MODIFY CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'y_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8976\\2371694481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price_range'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test-set accuarcy score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'y_test.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('y_test.csv')['price_range'].values\n",
    "\n",
    "print('Test-set accuarcy score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** We will check your result for Question 3 manually *** (5 points)\n",
      "*** We will check your result for Question 6 manually *** (20 points)\n",
      "Approximate score range: 45.0 ~ 70.0\n",
      "*** This score is only for reference ***\n"
     ]
    }
   ],
   "source": [
    "def discrete_checker(score, thres, clf, name, x_train, y_train, x_test, y_test):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "        return score\n",
    "    else:\n",
    "        print(f\"{name} failed\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def patient_checker(score, thres, CLS, kwargs, name,\n",
    "                    x_train, y_train, x_test, y_test, patient=10):\n",
    "    while patient > 0:\n",
    "        patient -= 1\n",
    "        clf = CLS(**kwargs)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "            return score\n",
    "    print(f\"{name} failed\")\n",
    "    print(\"Considering the randomness, we will check it manually\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\"\n",
    "    df = pd.read_csv(\n",
    "        file_url,\n",
    "        names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "               \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
    "    )\n",
    "\n",
    "    df['Target'] = (df[\"Age\"] > 15).astype(int)\n",
    "    df = df.drop(labels=[\"Age\"], axis=\"columns\")\n",
    "\n",
    "    train_idx = range(0, len(df), 10)\n",
    "    test_idx = range(1, len(df), 20)\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "    x_train = train_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    feature_names = x_train.columns.values\n",
    "    x_train = x_train.values\n",
    "    y_train = train_df['Target'].values\n",
    "\n",
    "    x_test = test_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    x_test = x_test.values\n",
    "    y_test = test_df['Target'].values\n",
    "    return x_train, y_train, x_test, y_test, feature_names\n",
    "\n",
    "\n",
    "score = 0\n",
    "\n",
    "data = np.array([1, 2])\n",
    "if abs(gini(data) - 0.5) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"gini test failed\")\n",
    "\n",
    "if abs(entropy(data) - 1) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"entropy test failed\")\n",
    "\n",
    "x_train, y_train, x_test, y_test, feature_names = load_dataset()\n",
    "\n",
    "score += discrete_checker(5, 0.9337,\n",
    "                          DecisionTree(criterion='gini', max_depth=3),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9036,\n",
    "                          DecisionTree(criterion='gini', max_depth=10),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=10)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9096,\n",
    "                          DecisionTree(criterion='entropy', max_depth=3),\n",
    "                          \"DecisionTree(criterion='entropy', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "print(\"*** We will check your result for Question 3 manually *** (5 points)\")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.91, AdaBoost, {\"n_estimators\": 10},\n",
    "    \"AdaBoost(n_estimators=10)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.87, AdaBoost, {\"n_estimators\": 100},\n",
    "    \"AdaBoost(n_estimators=100)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=10, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 100, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=100, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.92, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": x_train.shape[1]},\n",
    "    \"RandomForest(n_estimators=10, max_features=n_features)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "print(\"*** We will check your result for Question 6 manually *** (20 points)\")\n",
    "print(\"Approximate score range:\", score, \"~\", score + 25)\n",
    "print(\"*** This score is only for reference ***\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
