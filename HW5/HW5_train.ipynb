{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9cf651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:30.881823Z",
     "iopub.status.busy": "2022-11-25T04:50:30.881165Z",
     "iopub.status.idle": "2022-11-25T04:50:32.983521Z",
     "shell.execute_reply": "2022-11-25T04:50:32.982295Z"
    },
    "papermill": {
     "duration": 2.109989,
     "end_time": "2022-11-25T04:50:32.986527",
     "exception": false,
     "start_time": "2022-11-25T04:50:30.876538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52fada5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:32.995956Z",
     "iopub.status.busy": "2022-11-25T04:50:32.994774Z",
     "iopub.status.idle": "2022-11-25T04:50:33.001735Z",
     "shell.execute_reply": "2022-11-25T04:50:33.000477Z"
    },
    "papermill": {
     "duration": 0.014176,
     "end_time": "2022-11-25T04:50:33.004252",
     "exception": false,
     "start_time": "2022-11-25T04:50:32.990076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./dataset/train\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49808be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "ALL_CHAR_SET = NUMBER + ALPHABET\n",
    "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
    "print(ALL_CHAR_SET_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b6db42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:33.012917Z",
     "iopub.status.busy": "2022-11-25T04:50:33.012513Z",
     "iopub.status.idle": "2022-11-25T04:50:33.023305Z",
     "shell.execute_reply": "2022-11-25T04:50:33.021968Z"
    },
    "papermill": {
     "duration": 0.017781,
     "end_time": "2022-11-25T04:50:33.025650",
     "exception": false,
     "start_time": "2022-11-25T04:50:33.007869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, data, root, captcha_len, return_filename=False):\n",
    "        self.data = data\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.captcha_len = captcha_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = cv2.imread(f\"{self.root}/{filename}\", cv2.IMREAD_GRAYSCALE)\n",
    "        #_,img = cv2.threshold(img,180,255,cv2.THRESH_BINARY)\n",
    "        #img = ~img\n",
    "        #img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations = 1)\n",
    "        #img = ~img\n",
    "        #img = scipy.ndimage.median_filter(img, (5, 1))\n",
    "        img = np.array(img)\n",
    "        if self.return_filename:\n",
    "            return torch.FloatTensor(img), filename\n",
    "        else:\n",
    "            return torch.FloatTensor(img), self.one_hot_encode(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def one_hot_encode(self, label):\n",
    "        onehot = [0] * (ALL_CHAR_SET_LEN * self.captcha_len)\n",
    "        for i, l in enumerate(label):\n",
    "            idx = ALL_CHAR_SET.index(l) + i * ALL_CHAR_SET_LEN\n",
    "            onehot[idx] = 1\n",
    "        return np.array(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c872bf98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:33.052439Z",
     "iopub.status.busy": "2022-11-25T04:50:33.051285Z",
     "iopub.status.idle": "2022-11-25T04:50:33.078651Z",
     "shell.execute_reply": "2022-11-25T04:50:33.077413Z"
    },
    "papermill": {
     "duration": 0.035192,
     "end_time": "2022-11-25T04:50:33.081577",
     "exception": false,
     "start_time": "2022-11-25T04:50:33.046385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_1 = []\n",
    "data_2 = []\n",
    "data_3 = []\n",
    "\n",
    "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if row[0].startswith(\"task1\"):\n",
    "            data_1.append(row)\n",
    "        elif row[0].startswith(\"task2\"):\n",
    "            data_2.append(row)\n",
    "        elif row[0].startswith(\"task3\"):\n",
    "            data_3.append(row)\n",
    "\n",
    "random.shuffle(data_1)\n",
    "random.shuffle(data_2)\n",
    "random.shuffle(data_3)\n",
    "\n",
    "train_data_1 = data_1[0:int(len(data_1)*0.8)]\n",
    "train_ds_1 = TaskDataset(train_data_1, root=TRAIN_PATH, captcha_len=1)\n",
    "train_dl_1 = DataLoader(train_ds_1, batch_size=100, num_workers=0, drop_last=True, shuffle=True)\n",
    "\n",
    "val_data_1 = data_1[int(len(data_1)*0.8):]\n",
    "val_ds_1 = TaskDataset(val_data_1, root=TRAIN_PATH, captcha_len=1)\n",
    "val_dl_1 = DataLoader(val_ds_1, batch_size=100, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "train_data_2 = data_2[0:int(len(data_2)*0.8)]\n",
    "train_ds_2 = TaskDataset(train_data_2, root=TRAIN_PATH, captcha_len=2)\n",
    "train_dl_2 = DataLoader(train_ds_2, batch_size=100, num_workers=0, drop_last=True, shuffle=True)\n",
    "\n",
    "val_data_2 = data_2[int(len(data_2)*0.8):]\n",
    "val_ds_2 = TaskDataset(val_data_2, root=TRAIN_PATH, captcha_len=2)\n",
    "val_dl_2 = DataLoader(val_ds_2, batch_size=100, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "train_data_3 = data_3[0:int(len(data_3)*0.8)]\n",
    "train_ds_3 = TaskDataset(train_data_3, root=TRAIN_PATH, captcha_len=4)\n",
    "train_dl_3 = DataLoader(train_ds_3, batch_size=100, num_workers=0, drop_last=True, shuffle=True)\n",
    "\n",
    "val_data_3 = data_3[int(len(data_3)*0.8):]\n",
    "val_ds_3 = TaskDataset(val_data_3, root=TRAIN_PATH, captcha_len=4)\n",
    "val_dl_3 = DataLoader(val_ds_3, batch_size=100, num_workers=0, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069dbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, output_len):\n",
    "        super(Model, self).__init__()\n",
    "        self.output_len = output_len\n",
    "        self.conv = nn.Sequential(\n",
    "                # batch*1*72*96 / batch*1*72*96\n",
    "                nn.Conv2d(1, 4, 3, padding=(1, 1)),\n",
    "                nn.BatchNorm2d(4),\n",
    "                nn.Conv2d(4, 16, 3, padding=(1, 1)),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                # batch*16*36*48\n",
    "                nn.Conv2d(16, 32, 3, padding=(1, 1)),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.Conv2d(32, 64, 3, padding=(1, 1)),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                # batch*64*18*24\n",
    "                nn.Conv2d(64, 128, 3, padding=(1, 1)),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.Conv2d(128, 256, 3, padding=(1, 1)),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(),\n",
    "                # batch*128*9*12\n",
    "                nn.Conv2d(256, 512, 3, padding=(1, 1)),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.Conv2d(512, 1024, 3, padding=(1, 1)),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(),\n",
    "                #batch*512*4*6\n",
    "                )\n",
    "        self.fc = nn.Linear(1024*4*4, 1024)\n",
    "        self.fc_task3 = nn.Linear(1024*4*6, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.out = nn.Linear(256, self.output_len)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, h, w = x.shape \n",
    "        x = x.view(b,1,h,w)\n",
    "        x = self.conv(x)\n",
    "        if self.output_len > 100:\n",
    "            x = x.view(-1, 1024*4*6)\n",
    "            x = self.fc_task3(x)\n",
    "        else:\n",
    "            x = x.view(-1, 1024*4*4)\n",
    "            x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9825cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfortask1 = Model(ALL_CHAR_SET_LEN * 1).to(device)\n",
    "optimizer = torch.optim.Adam(modelfortask1.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738e1071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:33.090477Z",
     "iopub.status.busy": "2022-11-25T04:50:33.090030Z",
     "iopub.status.idle": "2022-11-25T04:54:08.645651Z",
     "shell.execute_reply": "2022-11-25T04:54:08.643963Z"
    },
    "papermill": {
     "duration": 215.563244,
     "end_time": "2022-11-25T04:54:08.648449",
     "exception": false,
     "start_time": "2022-11-25T04:50:33.085205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]\n",
      "accuracy (validation): tensor(0.9975, device='cuda:0')\n",
      "Epoch [2]\n",
      "accuracy (validation): tensor(0.9992, device='cuda:0')\n",
      "Epoch [3]\n",
      "accuracy (validation): tensor(0.9997, device='cuda:0')\n",
      "Epoch [4]\n",
      "accuracy (validation): tensor(0.9983, device='cuda:0')\n",
      "Epoch [5]\n",
      "accuracy (validation): tensor(0.9976, device='cuda:0')\n",
      "Epoch [6]\n",
      "accuracy (validation): tensor(0.9994, device='cuda:0')\n",
      "Epoch [7]\n",
      "accuracy (validation): tensor(0.9994, device='cuda:0')\n",
      "Epoch [8]\n",
      "accuracy (validation): tensor(0.9971, device='cuda:0')\n",
      "Epoch [9]\n",
      "accuracy (validation): tensor(0.9992, device='cuda:0')\n",
      "Epoch [10]\n",
      "accuracy (validation): tensor(0.9996, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print(f\"Epoch [{epoch+1}]\")\n",
    "    modelfortask1.train()\n",
    "    for image, label in train_dl_1:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device, dtype=torch.float)\n",
    "        \n",
    "        pred = modelfortask1(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    modelfortask1.eval()\n",
    "    for image, label in val_dl_1:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device, dtype=torch.float)\n",
    "        \n",
    "        pred = modelfortask1(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        pred = torch.argmax(pred.T[0:10], dim=0)\n",
    "        label = torch.argmax(label.T[0:10], dim=0)\n",
    "\n",
    "        sample_count += len(image)\n",
    "        correct_count += (label == pred).sum()\n",
    "\n",
    "    acc = correct_count / sample_count\n",
    "    print(\"accuracy (validation):\", acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        PATH_1 = \"task_1_model.pt\"\n",
    "        torch.save({\n",
    "            'model_state_dict': modelfortask1.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, PATH_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320848d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfortask2 = Model(ALL_CHAR_SET_LEN * 2).to(device)\n",
    "optimizer = torch.optim.Adam(modelfortask2.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf653f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]\n",
      "accuracy (validation): tensor(0.9965, device='cuda:0')\n",
      "Epoch [2]\n",
      "accuracy (validation): tensor(0.9980, device='cuda:0')\n",
      "Epoch [3]\n",
      "accuracy (validation): tensor(0.9973, device='cuda:0')\n",
      "Epoch [4]\n",
      "accuracy (validation): tensor(0.9958, device='cuda:0')\n",
      "Epoch [5]\n",
      "accuracy (validation): tensor(0.9980, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print(f\"Epoch [{epoch+1}]\")\n",
    "    modelfortask2.train()\n",
    "    for image, label in train_dl_2:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device, dtype=torch.float)\n",
    "        \n",
    "        pred = modelfortask2(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    modelfortask2.eval()\n",
    "    for image, label in val_dl_2:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device, dtype=torch.float)\n",
    "        \n",
    "        pred = modelfortask2(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "            \n",
    "        pred_1 = torch.argmax(pred.T[0:ALL_CHAR_SET_LEN], dim=0)\n",
    "        label_1 = torch.argmax(label.T[0:ALL_CHAR_SET_LEN], dim=0)\n",
    "        pred_2 = torch.argmax(pred.T[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2], dim=0)\n",
    "        label_2 = torch.argmax(label.T[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2], dim=0)\n",
    "        flag = torch.logical_and((label_1 == pred_1), (label_2 == pred_2))\n",
    "        \n",
    "        sample_count += len(image)\n",
    "        correct_count += (flag).sum()\n",
    "\n",
    "    acc = correct_count / sample_count\n",
    "    print(\"accuracy (validation):\", acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        PATH_2 = \"task_2_model.pt\"\n",
    "        torch.save({\n",
    "            'model_state_dict': modelfortask2.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, PATH_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d586ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfortask3 = Model(ALL_CHAR_SET_LEN * 4).to(device)\n",
    "optimizer = torch.optim.Adam(modelfortask3.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff19805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]\n",
      "accuracy (validation): tensor(0.6194, device='cuda:0')\n",
      "Epoch [2]\n",
      "accuracy (validation): tensor(0.8296, device='cuda:0')\n",
      "Epoch [3]\n",
      "accuracy (validation): tensor(0.8847, device='cuda:0')\n",
      "Epoch [4]\n",
      "accuracy (validation): tensor(0.9125, device='cuda:0')\n",
      "Epoch [5]\n",
      "accuracy (validation): tensor(0.9271, device='cuda:0')\n",
      "Epoch [6]\n",
      "accuracy (validation): tensor(0.9395, device='cuda:0')\n",
      "Epoch [7]\n",
      "accuracy (validation): tensor(0.9467, device='cuda:0')\n",
      "Epoch [8]\n",
      "accuracy (validation): tensor(0.9532, device='cuda:0')\n",
      "Epoch [9]\n",
      "accuracy (validation): tensor(0.9560, device='cuda:0')\n",
      "Epoch [10]\n",
      "accuracy (validation): tensor(0.9587, device='cuda:0')\n",
      "Epoch [11]\n",
      "accuracy (validation): tensor(0.9623, device='cuda:0')\n",
      "Epoch [12]\n",
      "accuracy (validation): tensor(0.9641, device='cuda:0')\n",
      "Epoch [13]\n",
      "accuracy (validation): tensor(0.9663, device='cuda:0')\n",
      "Epoch [14]\n",
      "accuracy (validation): tensor(0.9671, device='cuda:0')\n",
      "Epoch [15]\n",
      "accuracy (validation): tensor(0.9684, device='cuda:0')\n",
      "Epoch [16]\n",
      "accuracy (validation): tensor(0.9702, device='cuda:0')\n",
      "Epoch [17]\n",
      "accuracy (validation): tensor(0.9718, device='cuda:0')\n",
      "Epoch [18]\n",
      "accuracy (validation): tensor(0.9724, device='cuda:0')\n",
      "Epoch [19]\n",
      "accuracy (validation): tensor(0.9725, device='cuda:0')\n",
      "Epoch [20]\n",
      "accuracy (validation): tensor(0.9730, device='cuda:0')\n",
      "Epoch [21]\n",
      "accuracy (validation): tensor(0.9739, device='cuda:0')\n",
      "Epoch [22]\n",
      "accuracy (validation): tensor(0.9739, device='cuda:0')\n",
      "Epoch [23]\n",
      "accuracy (validation): tensor(0.9749, device='cuda:0')\n",
      "Epoch [24]\n",
      "accuracy (validation): tensor(0.9747, device='cuda:0')\n",
      "Epoch [25]\n",
      "accuracy (validation): tensor(0.9752, device='cuda:0')\n",
      "Epoch [26]\n",
      "accuracy (validation): tensor(0.9758, device='cuda:0')\n",
      "Epoch [27]\n",
      "accuracy (validation): tensor(0.9758, device='cuda:0')\n",
      "Epoch [28]\n",
      "accuracy (validation): tensor(0.9763, device='cuda:0')\n",
      "Epoch [29]\n",
      "accuracy (validation): tensor(0.9772, device='cuda:0')\n",
      "Epoch [30]\n",
      "accuracy (validation): tensor(0.9773, device='cuda:0')\n",
      "Epoch [31]\n",
      "accuracy (validation): tensor(0.9774, device='cuda:0')\n",
      "Epoch [32]\n",
      "accuracy (validation): tensor(0.9772, device='cuda:0')\n",
      "Epoch [33]\n",
      "accuracy (validation): tensor(0.9783, device='cuda:0')\n",
      "Epoch [34]\n",
      "accuracy (validation): tensor(0.9780, device='cuda:0')\n",
      "Epoch [35]\n",
      "accuracy (validation): tensor(0.9787, device='cuda:0')\n",
      "Epoch [36]\n",
      "accuracy (validation): tensor(0.9787, device='cuda:0')\n",
      "Epoch [37]\n",
      "accuracy (validation): tensor(0.9788, device='cuda:0')\n",
      "Epoch [38]\n",
      "accuracy (validation): tensor(0.9790, device='cuda:0')\n",
      "Epoch [39]\n",
      "accuracy (validation): tensor(0.9789, device='cuda:0')\n",
      "Epoch [40]\n",
      "accuracy (validation): tensor(0.9797, device='cuda:0')\n",
      "Epoch [41]\n",
      "accuracy (validation): tensor(0.9794, device='cuda:0')\n",
      "Epoch [42]\n",
      "accuracy (validation): tensor(0.9808, device='cuda:0')\n",
      "Epoch [43]\n",
      "accuracy (validation): tensor(0.9800, device='cuda:0')\n",
      "Epoch [44]\n",
      "accuracy (validation): tensor(0.9796, device='cuda:0')\n",
      "Epoch [45]\n",
      "accuracy (validation): tensor(0.9809, device='cuda:0')\n",
      "Epoch [46]\n",
      "accuracy (validation): tensor(0.9802, device='cuda:0')\n",
      "Epoch [47]\n",
      "accuracy (validation): tensor(0.9803, device='cuda:0')\n",
      "Epoch [48]\n",
      "accuracy (validation): tensor(0.9804, device='cuda:0')\n",
      "Epoch [49]\n",
      "accuracy (validation): tensor(0.9814, device='cuda:0')\n",
      "Epoch [50]\n",
      "accuracy (validation): tensor(0.9810, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    print(f\"Epoch [{epoch+1}]\")\n",
    "    modelfortask3.train()\n",
    "    for image, label in train_dl_3:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device, dtype=torch.float)\n",
    "        \n",
    "        pred = modelfortask3(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    modelfortask3.eval()\n",
    "    for image, label in val_dl_3:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device, dtype=torch.float)\n",
    "        \n",
    "        pred = modelfortask3(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "            \n",
    "        pred_1 = torch.argmax(pred.T[0:ALL_CHAR_SET_LEN], dim=0)\n",
    "        label_1 = torch.argmax(label.T[0:ALL_CHAR_SET_LEN], dim=0)\n",
    "        pred_2 = torch.argmax(pred.T[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2], dim=0)\n",
    "        label_2 = torch.argmax(label.T[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2], dim=0)\n",
    "        pred_3 = torch.argmax(pred.T[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3], dim=0)\n",
    "        label_3 = torch.argmax(label.T[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3], dim=0)\n",
    "        pred_4 = torch.argmax(pred.T[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4], dim=0)\n",
    "        label_4 = torch.argmax(label.T[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4], dim=0)\n",
    "        \n",
    "        flag_1 = torch.logical_and((label_1 == pred_1), (label_2 == pred_2))\n",
    "        flag_2 = torch.logical_and((label_3 == pred_3), (label_4 == pred_4))\n",
    "        flag = torch.logical_and(flag_1, flag_2)\n",
    "        \n",
    "        sample_count += len(image)\n",
    "        correct_count += (flag).sum()\n",
    "    \n",
    "    acc = correct_count / sample_count\n",
    "    print(\"accuracy (validation):\", acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        PATH_3 = \"task_3_model.pt\"\n",
    "        torch.save({\n",
    "            'model_state_dict': modelfortask3.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, PATH_3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 242.076508,
   "end_time": "2022-11-25T04:54:16.697471",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-25T04:50:14.620963",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
